{"version":3,"sources":["images/brds.JPG","images/lossresnet18.JPG","images/lossresnet50.JPG","images/lossaug.JPG","App.js","reportWebVitals.js","index.js"],"names":["App","className","href","target","rel","src","birdImages","alt","loss18","loss50","lossAug","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"4JAAe,G,UAAA,IAA0B,kCCA1B,MAA0B,yCCA1B,MAA0B,yCCA1B,MAA0B,oC,OC2J1BA,MArJf,WACE,OACE,sBAAKC,UAAU,MAAf,UACE,sBAAKA,UAAU,QAAf,UACE,oEACA,iDAEF,sBAAKA,UAAU,UAAf,UACE,8CACA,0EAA4C,mBAAGC,KAAK,wFAAwFC,OAAO,SAASC,IAAI,sBAApH,kBAA5C,OACA,6CACA,2JAGA,6CACA,mGACoE,mBAAGF,KAAK,0CAA0CC,OAAO,SAASC,IAAI,sBAAtE,kBADpE,OAGA,qBAAKC,IAAKC,EAAYC,IAAI,QAE5B,sBAAKN,UAAU,UAAf,UACE,0CACA,iDACA,+BACE,8DACA,mDACA,sDACA,0CACA,6CAEF,6CACA,+BACE,4GACA,gLAIA,4VAMA,gIAEF,mDACA,+BACE,wLAIA,wLAIA,oMAKF,qDACA,+BACE,4ZAMA,mXAKA,4hBAOA,6OAMJ,sBAAKA,UAAU,UAAf,UACE,yCACA,0CACA,oDAAsB,8CACtB,sDAAwB,8CACxB,6DAA+B,4CAC/B,4CACA,qBAAKI,IAAKG,EAAQD,IAAI,KACtB,0CACA,oDAAsB,8CACtB,sDAAwB,8CACxB,6DAA+B,4CAC/B,4CACA,qBAAKF,IAAKI,EAAQF,IAAI,KACtB,8FACA,oDAAsB,8CACtB,sDAAwB,8CACxB,6DAA+B,4CAC/B,4CACA,qBAAKF,IAAKK,EAASH,IAAI,QAEzB,sBAAKN,UAAU,UAAf,UACE,4CACA,qDACA,8oBAQA,gDACA,+BACE,6FAGA,8GAGA,gEAGA,0IAIF,sDACA,+BACE,+MAIA,qNCrIKU,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,K","file":"static/js/main.fc5d467f.chunk.js","sourcesContent":["export default __webpack_public_path__ + \"static/media/brds.58e760d0.JPG\";","export default __webpack_public_path__ + \"static/media/lossresnet18.2d4a6ab7.JPG\";","export default __webpack_public_path__ + \"static/media/lossresnet50.829ccc0b.JPG\";","export default __webpack_public_path__ + \"static/media/lossaug.39f6ece7.JPG\";","import './App.css';\nimport birdImages from './images/brds.JPG';\nimport loss18 from './images/lossresnet18.JPG';\nimport loss50 from './images/lossresnet50.JPG';\nimport lossAug from './images/lossaug.JPG';\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <div className=\"title\">\n        <h1>Bird Classifier Kaggle Competition</h1>\n        <p>By Tyler Wong</p>\n      </div>\n      <div className=\"section\">\n        <h2>Introduction</h2>\n        <p>Source code is available on Google Colab <a href=\"https://colab.research.google.com/drive/11C7hILEP2-ia_eoXcKmwOan7IvMD4U7t?usp=sharing\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.</p>\n        <h3>The Problem</h3>\n        <p>\n          The problem I am trying to solve is how to accurately and efficiently identify hundreds of bird species based on pictures.\n        </p>\n        <h3>The Dataset</h3>\n        <p>\n          The dataset from the bird classification Kaggle competition found <a href=\"https://www.kaggle.com/c/birds21sp/data\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.\n        </p>\n        <img src={birdImages} alt=\"\" />\n      </div>\n      <div className=\"section\">\n        <h2>Approach</h2>\n        <h3>Techniques Used</h3>\n        <ul>\n          <li>Convolutional Neural Network</li>\n          <li>Data augmentation</li>\n          <li>Image preproccessing</li>\n          <li>ResNet18</li>\n          <li>ResNet50</li>\n        </ul>\n        <h3>The Process</h3>\n        <ol>\n          <li>First I preproccessed the data to resize all the images to 224x224 pixels.</li>\n          <li>\n            Then I loaded and augmented the data. Augmentations included random cropping,\n            random horizontal flipping, gaussian noise, and random rotation.\n          </li>\n          <li>\n            Then I used a pretrained model and retrained it using the dataset. Throughout retraining\n            I experimented with parameters such as learning rate, weight decay, batch size, and number of\n            epochs in order to optimize my model. Additionally, I used a random 10% of the training data\n            as a validation set to check accuracy.\n          </li>\n          <li>Lastly I created predictions on the test data and submitted them to the kaggle competition.</li>\n        </ol>\n        <h3>Why this approach</h3>\n        <ul>\n          <li>\n            By preproccessing my images it greatly speeds up dataloading because the dataloader wouldn't have to\n            resize all of the images each time it loads them.\n          </li>\n          <li>\n            By using data augmentation it would decrease overfitting\n            of my model to the training data because it would be harder for the model to memorize images.\n          </li>\n          <li>\n            By using a pretrained model I wouldn't have to create my own model, it would be quicker to train,\n            and it would have preadjusted weights for increased accuracy.\n          </li>\n        </ul>\n        <h3>Problems I ran into</h3>\n        <ul>\n          <li>\n            The dataset had a large variety of sizes of images and many of them were very large, which made it\n            take a long time to copy all of the images onto the session storage each time I started Google Colab.\n            To fix this I zipped all of the data into a zip file and unzipped it into the session storage instead\n            of copying it, this reduced roughly 2 hours of wait time down to 3 minutes.\n          </li>\n          <li>\n            Resizing the data using a dataloader took significant amount of time and slowed down training a lot.\n            To fixed this problem I preproccessed all of the images in the dataset and resized them to 224x224 pixels.\n            This made the whole dataset smaller and greatly increased the speed of training (from ~25 min per epoch to ~3 minutes per epoch).\n          </li>\n          <li>\n            My model consistently overfit to my training data. To try and fix this I added batch normalization to\n            the last fully connected layer, increased the weight decay, and used more data augmentation.\n            On top of random cropping and random flipping I also added random gaussian noise and random rotation.\n            These solutions decreased the overfitting, however, they also decreased my overall accuracy and I ran out\n            of GPU runtime before I could adjust other parameters like learning rate in order to possibly fix this.\n          </li>\n          <li>\n            I ran out of time on the GPU runtime in Google Colab multiple times, and each consecutive\n            time I had less GPU time available. This caused me to not be able to fine tune my model as discussed above.\n          </li>\n        </ul>\n      </div>\n      <div className=\"section\">\n        <h2>Results</h2>\n        <h3>ResNet18</h3>\n        <p>Training accuracy: <span>91.142%</span></p>\n        <p>Validation accuracy: <span>72.856%</span></p>\n        <p>Kaggle submission accuracy: <span>72.6%</span></p>\n        <p>Loss Graph:</p>\n        <img src={loss18} alt=\"\" />\n        <h3>ResNet50</h3>\n        <p>Training accuracy: <span>93.398%</span></p>\n        <p>Validation accuracy: <span>78.562%</span></p>\n        <p>Kaggle submission accuracy: <span>77.7%</span></p>\n        <p>Loss Graph:</p>\n        <img src={loss50} alt=\"\" />\n        <h3>ResNet50 with more data augmentation and batch normalization</h3>\n        <p>Training accuracy: <span>85.451%</span></p>\n        <p>Validation accuracy: <span>72.901%</span></p>\n        <p>Kaggle submission accuracy: <span>74.5%</span></p>\n        <p>Loss Graph:</p>\n        <img src={lossAug} alt=\"\" />\n      </div>\n      <div className=\"section\">\n        <h2>Discussion</h2>\n        <h3>What worked and why</h3>\n        <p>What got me the highest testing accuracy was using the pretrained ResNet50 model with\n          random flipping, random cropping, and a learning rate starting at 0.01 and decreasing\n          at about 0.001 per epoch. This worked well was because with the larger model of ResNet50\n          it has more layers which means that it can track and identify more features in the images.\n          Although it overfit significantly, with some data augmentation of random cropping and\n          random flipping it allowed this overfitting to decrease enough where the testing accuracy\n          could be closer to the training accuracy, but the training accuracy could still be very high.\n        </p>\n        <h3>What I learned</h3>\n        <ul>\n          <li>\n            How to use pytorch, CNNs in pytorch, and pretrained models.\n          </li>\n          <li>\n            How to preproccess images and the importance of it to speed up data loading.\n          </li>\n          <li>\n            Ways to deal with overfitting.\n          </li>\n          <li>\n            How to use a validation set to check accuracy and make adjustments before creating a full prediction.\n          </li>\n        </ul>\n        <h3>Further Applications</h3>\n        <ul>\n          <li>\n            This project and the ideas of using a pretrained CNNs could be applied to classiying other images,\n            specifically most directly for classifying other species of other animals.\n          </li>\n          <li>\n            The ideas in this project could also be used for object detection. This project could even be used as\n            the classification portion of the R-CNN model for object detection.\n          </li>\n        </ul>\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}